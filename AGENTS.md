# Developer & Agent Guide: AI Agent System

Welcome! This document provides the essential information for agents or developers who want to maintain, extend, or interact with this codebase.

## System Architecture

The system follows a modular architecture:
- **`Engine`**: Orchestrates the conversation loop, command parsing, and tool execution.
- **`Provider`**: Abstract interface for LLM communication (initially implemented via [Google GenAI SDK](agent_system/providers/google_provider.py)).
- **`Channel`**: Abstract interface for I/O.
    - [Terminal Channel](agent_system/channels/terminal_channel.py): Standard console I/O.
    - [Telegram Channel](agent_system/channels/telegram_channel.py): Remote I/O via Telegram Bot API.
- **`Persistence`**: Handles JSONL session logging and state management, including `thought_signature` preservation.

## Interface & Slash Commands

The agent supports built-in slash commands for management and utilities:

- `/help`: Show available commands.
- `/usage`: Show token usage for the current provider.
- `/compact`: Compact conversation history into a concise summary to save context space.
- `/clear`: Clear conversation history and start a new session file.
- `/reset`: Start a new session and completely empty the workspace.
- `/new [title]`: Start a new session, optionally with a title.
- `/list`: List all available sessions.
- `/switch <index>`: Switch to a specific session by its index.
- `/name <title>`: Set or change the title of the current session.
- `/reload`: Reload the system prompt and all dynamic tools without restarting.
- `/exit` or `/quit`: Terminate the session.

## The Dynamic Tool System

The most extensible part of this system is the **Dynamic Tooling layer**. Tools are discovered and loaded at runtime from the `tools/` directory.

### 1. How Tools are Loaded
- On startup, the `Engine` scans the `tools/` directory for `.py` files.
- It uses `importlib.util` to dynamically import each module.
- A module is recognized as a valid tool if it exports two specific items: `SCHEMA` and `execute`.

### 2. Tool Module Interface
To add a new tool, create a `.py` file (e.g., `tools/my_tool.py`) with the following structure:

```python
# tools/my_tool.py

# 1. The SCHEMA (Google GenAI function declaration format)
SCHEMA = {
    "name": "my_tool_name",
    "display_name": "Running my tool", # Optional: shown to user during execution
    "description": "Explains what the tool does to the LLM.",
    "parameters": {
        "type": "OBJECT",
        "properties": {
            "param1": {"type": "STRING", "description": "Description of param1."},
        },
        "required": ["param1"]
    }
}

# 2. The Execute Function
def execute(params: dict) -> str:
    # params['_workspace'] is automatically injected by the engine
    p1 = params.get("param1")
    return f"Result: {p1}"
```

### 3. Built-in Tools Catalog

| Tool | Description | Status |
| :--- | :--- | :--- |
| `get_current_time` | Returns the current system date and time. | Stable |
| `web_search` | Performs web searches via DuckDuckGo (text, images, news, etc.). | Stable |
| `python_analyser` | Runs Python code in a sandboxed Docker container with full root access and networking. | High-Perf |
| `schedule_task` | Schedules a task (prompt) to be executed at a specific time or recurrently (cron). | New |
| `list_tasks` | Lists all currently scheduled tasks. | New |
| `delete_task` | Deletes a scheduled task by its ID. | New |
| `text_to_speech` | Converts text into speech audio (WAV) using the Piper TTS engine. | New |
| `transcribe_audio` | Transcribes audio files into text using the Faster-Whisper model. | New |

#### Special Engine Features for Tools:
- **`display_name`**: If present in `SCHEMA`, the engine uses this string to notify the user (e.g., "Running Python code...") instead of the raw tool name.
- **`_workspace` Injection**: The engine automatically adds a `_workspace` key to the `params` dictionary, providing the absolute path to the persistent workspace directory on the host.
- **`_host_workspace` Injection**: If the `WORKSPACE_HOST_PATH` environment variable is set, it's injected into tools to help map paths if the agent itself is running in a container.
- **`_scheduler` Injection**: The `Scheduler` instance is injected into tools, allowing them to manage scheduled tasks directly.

## The Output Pipeline

The system includes an automatic pipeline for delivering files generated by tools (especially `python_analyser`):
1. Tools should save deliverables to `/workspace/output` (within the sandbox).
2. The `Engine` scans this directory after each tool execution.
3. Any files found are automatically moved to `/workspace/processed/`.
4. The files are then sent to the user via the active channel.

## Safe Execution & Error Handling

The system is designed to be resilient against tool failures:

### 1. Load-time Isolation
The `Engine` wraps tool loading in a `try...except` block. If a tool file has syntax errors or top-level bugs, the engine will:
- Log the error.
- Skip the broken tool.
- Continue loading other tools and start the system normally.

### 2. Runtime Execution Guards
Each tool execution is also wrapped in a `try...except` block within the conversation loop. If a tool crashes during execution:
- The error is captured and displayed to the user.
- The error message is passed back to the LLM as a tool result, allowing it to potentially correct the error or try a different approach.
- The agent system itself remains stable and ready for the next command.

### 3. Process Isolation (Python Analyser)
The `python_analyser` tool runs code inside a Docker container. This provide additional isolation:
- Crashes or infinite loops inside the container do not affect the host system.
- Memory and CPU usage can be capped via Docker configuration.
- Filesystem access is restricted to the mapped `/workspace` volume.

## Setup & Environment

To get the system up and running with all dependencies (including Docker images for the Python Analyser), use the provided setup script:

```bash
# Run the automated setup
bash scripts/setup.sh

# Activate the environment and run the agent
source venv/bin/activate
python main.py
```

### Telegram Bot Setup
If you want to use the agent via Telegram:
1. Run the Telegram setup script:
   ```bash
   ./venv/bin/python scripts/setup_telegram.py
   ```
2. Follow the instructions to configure your `TELEGRAM_BOT_TOKEN` and `TELEGRAM_CHAT_ID`.
3. Update `config.json` to use the telegram channel:
   ```json
   "channel": "telegram"
   ```

### Manual Configuration
- **API Keys**: Ensure your `GOOGLE_API_KEY` is set in the `.env` file.
- **Docker**: The `python_analyser` tool requires Docker to be installed and running.
- **Hot-Reloading**: Use **/reload** to refresh tools after modification.

## Guidelines for Agents & Developers

### 1. Environment Policy
> [!IMPORTANT]
> **Always use the project's virtual environment (`venv/`) for running any commands, scripts, or tests.**
> This project has specific dependencies (e.g., `requests`, `google-genai`) that are ONLY installed in the `venv`. Failure to use the `venv` will result in `ModuleNotFoundError` errors.

- **To run a script directly**: Use `./venv/bin/python path/to/script.py`
- **To run tests**: Use `./venv/bin/python -m unittest path/to/test.py`
- **To run main application**: Use `./venv/bin/python main.py`

### 2. Maintenance & Testing

To ensure system stability, especially when modifying core components or channels, the repository includes a suite of automated tests. 

#### Running Tests
Execute the tests directly using the Python interpreter in the `venv`:

```bash
# Run all formatting tests
./venv/bin/python verification/test_formatting.py

# Run Telegram channel logic tests
./venv/bin/python verification/test_telegram_channel.py

# Run audio message support tests
./venv/bin/python verification/test_audio_support.py
```

> [!TIP]
> Running tests via `./venv/bin/python` ensures that all dependencies listed in `requirements.txt` are correctly found without needing to manually activate the shell.

